{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transferLearning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "_4zUwWp3kAEU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning\n",
        "\n",
        "These two major transfer learning scenarios look as follows:\n",
        "\n",
        "\n",
        "\n",
        "1.   Finetuning the convnet: Instead of random initializaion, we initialize the network with a pretrained network, like the one that is trained on imagenet 1000 dataset. Rest of the training looks as usual.\n",
        "2.   ConvNet as fixed feature extractor: Here, we will freeze the weights for all of the network except that of the final fully connected layer. This last fully connected layer is replaced with a new one with random weights and only this layer is trained.\n"
      ]
    },
    {
      "metadata": {
        "id": "iKtVMrK1kXmz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "792f49c4-4d82-423e-b01f-90eb210a3876"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 33kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x593ca000 @  0x7f667e5332a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n",
            "\u001b[?25hCollecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 21.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Installing collected packages: torch, pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0 torch-0.4.1 torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZEXxLempkgM8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://dl.dropboxusercontent.com/s/b3khjfddz5wpvai/alzhdset.zip?dl=0 -O alzhdset.zip;\n",
        "!unzip alzhdset.zip;\n",
        "!mv \"Alzheimer's Dataset\" alzhdset\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i7cI6e-1lCgF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "plt.ion()   # interactive mode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bfa-eA2LkvWa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DAmYOV1plG9A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = datasets.ImageFolder(\"./alzhdset/Train\",transform=data_transforms['train'])\n",
        "test_data = datasets.ImageFolder(\"./alzhdset/Test\",transform=data_transforms['test'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yiuNn61-43M7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_sizes = {'train': len(train_data), 'test': len(test_data)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "039ZvfxGl1uS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "n_iters = 3000\n",
        "num_epochs = int(n_iters / (5121/batch_size))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H58tHOXemODI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d2cf976-ac12-429e-cd4c-c6d3188f67a0"
      },
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "print(class_names)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "btKe2ga2nwBf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Using ResNet18"
      ]
    },
    {
      "metadata": {
        "id": "DEIQnzxFn9L6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "resnet18 = models.resnet18(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FESB2uhxn-8u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1476
        },
        "outputId": "152a740a-13b1-4c67-e264-bc998d4ded57"
      },
      "cell_type": "code",
      "source": [
        "print(resnet18)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wbj_LC5B3uEp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The last fc layer outputs 1000 features but we need only 4, so gotta modify it."
      ]
    },
    {
      "metadata": {
        "id": "mpseimEnrdT2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_ftrs = resnet18.fc.in_features\n",
        "resnet18.fc = nn.Linear(num_ftrs, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j2WwiNEF39-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1476
        },
        "outputId": "d8d35d61-1a79-4887-e8c9-a3d72abe3474"
      },
      "cell_type": "code",
      "source": [
        "print(resnet18)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
            "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qil8gNo2r_i_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "resnet18 = resnet18.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet18.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-gEbX0UbuR6P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_DpZcpDauo7Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataloaders = {\n",
        "    'train': train_loader,\n",
        "    'test': test_loader\n",
        "}\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and testing phase\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'test' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gHp30kC7vFFr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2657
        },
        "outputId": "85fdd00c-4e09-4a19-d249-323849f46bbe"
      },
      "cell_type": "code",
      "source": [
        "resnet18 = train_model(resnet18, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=30)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/29\n",
            "----------\n",
            "train Loss: 0.8030 Acc: 0.6233\n",
            "test Loss: 0.8547 Acc: 0.6114\n",
            "\n",
            "Epoch 1/29\n",
            "----------\n",
            "train Loss: 0.7929 Acc: 0.6290\n",
            "test Loss: 0.8332 Acc: 0.6013\n",
            "\n",
            "Epoch 2/29\n",
            "----------\n",
            "train Loss: 0.7869 Acc: 0.6309\n",
            "test Loss: 0.8378 Acc: 0.6106\n",
            "\n",
            "Epoch 3/29\n",
            "----------\n",
            "train Loss: 0.7928 Acc: 0.6259\n",
            "test Loss: 0.8340 Acc: 0.5981\n",
            "\n",
            "Epoch 4/29\n",
            "----------\n",
            "train Loss: 0.7809 Acc: 0.6405\n",
            "test Loss: 0.8510 Acc: 0.6091\n",
            "\n",
            "Epoch 5/29\n",
            "----------\n",
            "train Loss: 0.7799 Acc: 0.6384\n",
            "test Loss: 0.8368 Acc: 0.6130\n",
            "\n",
            "Epoch 6/29\n",
            "----------\n",
            "train Loss: 0.7892 Acc: 0.6284\n",
            "test Loss: 0.8298 Acc: 0.5997\n",
            "\n",
            "Epoch 7/29\n",
            "----------\n",
            "train Loss: 0.7759 Acc: 0.6413\n",
            "test Loss: 0.8427 Acc: 0.5848\n",
            "\n",
            "Epoch 8/29\n",
            "----------\n",
            "train Loss: 0.7686 Acc: 0.6384\n",
            "test Loss: 0.8467 Acc: 0.6114\n",
            "\n",
            "Epoch 9/29\n",
            "----------\n",
            "train Loss: 0.7747 Acc: 0.6335\n",
            "test Loss: 0.8362 Acc: 0.5966\n",
            "\n",
            "Epoch 10/29\n",
            "----------\n",
            "train Loss: 0.7791 Acc: 0.6376\n",
            "test Loss: 0.8309 Acc: 0.6036\n",
            "\n",
            "Epoch 11/29\n",
            "----------\n",
            "train Loss: 0.7772 Acc: 0.6364\n",
            "test Loss: 0.8267 Acc: 0.6083\n",
            "\n",
            "Epoch 12/29\n",
            "----------\n",
            "train Loss: 0.7757 Acc: 0.6458\n",
            "test Loss: 0.8343 Acc: 0.5958\n",
            "\n",
            "Epoch 13/29\n",
            "----------\n",
            "train Loss: 0.7749 Acc: 0.6440\n",
            "test Loss: 0.8340 Acc: 0.5973\n",
            "\n",
            "Epoch 14/29\n",
            "----------\n",
            "train Loss: 0.7825 Acc: 0.6415\n",
            "test Loss: 0.8330 Acc: 0.5997\n",
            "\n",
            "Epoch 15/29\n",
            "----------\n",
            "train Loss: 0.7747 Acc: 0.6434\n",
            "test Loss: 0.8341 Acc: 0.6052\n",
            "\n",
            "Epoch 16/29\n",
            "----------\n",
            "train Loss: 0.7866 Acc: 0.6294\n",
            "test Loss: 0.8465 Acc: 0.6067\n",
            "\n",
            "Epoch 17/29\n",
            "----------\n",
            "train Loss: 0.7802 Acc: 0.6260\n",
            "test Loss: 0.8356 Acc: 0.6059\n",
            "\n",
            "Epoch 18/29\n",
            "----------\n",
            "train Loss: 0.7813 Acc: 0.6298\n",
            "test Loss: 0.8455 Acc: 0.6138\n",
            "\n",
            "Epoch 19/29\n",
            "----------\n",
            "train Loss: 0.7813 Acc: 0.6343\n",
            "test Loss: 0.8345 Acc: 0.5911\n",
            "\n",
            "Epoch 20/29\n",
            "----------\n",
            "train Loss: 0.7764 Acc: 0.6350\n",
            "test Loss: 0.8323 Acc: 0.6059\n",
            "\n",
            "Epoch 21/29\n",
            "----------\n",
            "train Loss: 0.7700 Acc: 0.6489\n",
            "test Loss: 0.8386 Acc: 0.5856\n",
            "\n",
            "Epoch 22/29\n",
            "----------\n",
            "train Loss: 0.7803 Acc: 0.6327\n",
            "test Loss: 0.8263 Acc: 0.6059\n",
            "\n",
            "Epoch 23/29\n",
            "----------\n",
            "train Loss: 0.7750 Acc: 0.6430\n",
            "test Loss: 0.8341 Acc: 0.6122\n",
            "\n",
            "Epoch 24/29\n",
            "----------\n",
            "train Loss: 0.7836 Acc: 0.6284\n",
            "test Loss: 0.8443 Acc: 0.6052\n",
            "\n",
            "Epoch 25/29\n",
            "----------\n",
            "train Loss: 0.7739 Acc: 0.6399\n",
            "test Loss: 0.8394 Acc: 0.6020\n",
            "\n",
            "Epoch 26/29\n",
            "----------\n",
            "train Loss: 0.7819 Acc: 0.6251\n",
            "test Loss: 0.8357 Acc: 0.5973\n",
            "\n",
            "Epoch 27/29\n",
            "----------\n",
            "train Loss: 0.7798 Acc: 0.6419\n",
            "test Loss: 0.8338 Acc: 0.5966\n",
            "\n",
            "Epoch 28/29\n",
            "----------\n",
            "train Loss: 0.7714 Acc: 0.6384\n",
            "test Loss: 0.8385 Acc: 0.5981\n",
            "\n",
            "Epoch 29/29\n",
            "----------\n",
            "train Loss: 0.7746 Acc: 0.6389\n",
            "test Loss: 0.8325 Acc: 0.6013\n",
            "\n",
            "Training complete in 29m 20s\n",
            "Best val Acc: 0.613761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NwAQ5FYFARSy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ConvNet(VGG16) as fixed feature extractor\n",
        "\n",
        "Here, we need to freeze all the network except the final layer. We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward()."
      ]
    },
    {
      "metadata": {
        "id": "u1jLPq4_AU_2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_conv = torchvision.models.vgg16_bn(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Xv9bLsHE-Cu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Alter last layer to output 4 features.\n",
        "num_feats = (model_conv.classifier[6].in_features)\n",
        "features = list(model_conv.classifier.children())\n",
        "features[-1] = nn.Linear(in_features=num_feats, out_features=4, bias=True)\n",
        "model_conv.classifier = nn.Sequential(*features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AkGaG8j0GX1p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1007
        },
        "outputId": "914b8558-64af-4cf9-d6d6-6be06ebdfc9f"
      },
      "cell_type": "code",
      "source": [
        "print(model_conv)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Dropout(p=0.5)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.5)\n",
            "    (6): Linear(in_features=4096, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-eqhmoPmC0qE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for param in model_conv.features.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qn7TvaW1JGTj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1024
        },
        "outputId": "65a6f75b-5ebd-49e0-e67c-6aa64452cca5"
      },
      "cell_type": "code",
      "source": [
        "# Verifying which are freezed and which aren't\n",
        "for name, child in model_conv.named_children():\n",
        "  for name_2, params in child.named_parameters():\n",
        "    print(name_2, params.requires_grad)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.weight False\n",
            "0.bias False\n",
            "1.weight False\n",
            "1.bias False\n",
            "3.weight False\n",
            "3.bias False\n",
            "4.weight False\n",
            "4.bias False\n",
            "7.weight False\n",
            "7.bias False\n",
            "8.weight False\n",
            "8.bias False\n",
            "10.weight False\n",
            "10.bias False\n",
            "11.weight False\n",
            "11.bias False\n",
            "14.weight False\n",
            "14.bias False\n",
            "15.weight False\n",
            "15.bias False\n",
            "17.weight False\n",
            "17.bias False\n",
            "18.weight False\n",
            "18.bias False\n",
            "20.weight False\n",
            "20.bias False\n",
            "21.weight False\n",
            "21.bias False\n",
            "24.weight False\n",
            "24.bias False\n",
            "25.weight False\n",
            "25.bias False\n",
            "27.weight False\n",
            "27.bias False\n",
            "28.weight False\n",
            "28.bias False\n",
            "30.weight False\n",
            "30.bias False\n",
            "31.weight False\n",
            "31.bias False\n",
            "34.weight False\n",
            "34.bias False\n",
            "35.weight False\n",
            "35.bias False\n",
            "37.weight False\n",
            "37.bias False\n",
            "38.weight False\n",
            "38.bias False\n",
            "40.weight False\n",
            "40.bias False\n",
            "41.weight False\n",
            "41.bias False\n",
            "0.weight True\n",
            "0.bias True\n",
            "3.weight True\n",
            "3.bias True\n",
            "6.weight True\n",
            "6.bias True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e0UWC_NvCmD1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model_conv = model_conv.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opoosed to before.\n",
        "optimizer_conv = optim.SGD(model_conv.classifier.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6RfBB-rZAVIy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "outputId": "20029759-dec2-4fdb-8707-2229729aeb0f"
      },
      "cell_type": "code",
      "source": [
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.9463 Acc: 0.5518\n",
            "test Loss: 0.9295 Acc: 0.5575\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.9384 Acc: 0.5571\n",
            "test Loss: 0.9073 Acc: 0.5841\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.9317 Acc: 0.5524\n",
            "test Loss: 0.9044 Acc: 0.5848\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.9213 Acc: 0.5573\n",
            "test Loss: 0.8909 Acc: 0.5919\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.9097 Acc: 0.5714\n",
            "test Loss: 0.9047 Acc: 0.5754\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.9112 Acc: 0.5614\n",
            "test Loss: 0.8968 Acc: 0.5856\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.9068 Acc: 0.5651\n",
            "test Loss: 0.8864 Acc: 0.5864\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.8993 Acc: 0.5731\n",
            "test Loss: 0.9063 Acc: 0.5809\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.9174 Acc: 0.5626\n",
            "test Loss: 0.8902 Acc: 0.5856\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.8998 Acc: 0.5681\n",
            "test Loss: 0.8980 Acc: 0.5848\n",
            "\n",
            "Training complete in 15m 26s\n",
            "Best val Acc: 0.591869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "py4JSbAKKa_b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Binary Classification"
      ]
    },
    {
      "metadata": {
        "id": "jM8HTF0lKff2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "da464c51-3fcd-4749-c9a6-4e6209bd8588"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V2fh1iftKfnp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "53f20758-b20b-4e2f-d945-3adae3e0ec8d"
      },
      "cell_type": "code",
      "source": [
        "!ls ./drive/\"My Drive\"/dataset"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I1NkhUmbKfzF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e12ddb8-e59f-40a2-b185-d23fcfe13f92"
      },
      "cell_type": "code",
      "source": [
        "cd ./drive/\"My Drive\"/dataset"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uEFzLiE6LjSB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe66e697-ef04-4f56-c767-40d067259680"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T2tY58UziV1O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "s71fFE3ULaG3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = datasets.ImageFolder(\"./train\",transform=data_transforms['train'])\n",
        "test_data = datasets.ImageFolder(\"./test\",transform=data_transforms['test'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "AuJ-yhojLaHo",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_sizes = {'train': len(train_data), 'test': len(test_data)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "txfAklomLaH6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "n_iters = 3000\n",
        "num_epochs = int(n_iters / (5121/batch_size))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "35e5547f-6ac3-4b13-cd03-09928844bf60",
        "id": "-m5AOP4VLaIF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "print(class_names)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ALZ', 'NALZ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I5h1G1jILLvh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Using ResNet.... taking forever... will go with VGG"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KNQGn46cORNv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Using VGG as feature extractor... that's taking even longer... better go woth resnet as feature extractor. I'm doomed! :("
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7hE951Z6i1a5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "resnet18 = models.resnet18(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yw9IOxVsjXnC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for param in resnet18.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FgPe48Bzi1bo",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_ftrs = resnet18.fc.in_features\n",
        "resnet18.fc = nn.Linear(num_ftrs, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YjW-ig0zjvPB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1094
        },
        "outputId": "22d2fee9-d49d-4f31-83e1-e9c09a42c93e"
      },
      "cell_type": "code",
      "source": [
        "for name, child in resnet18.named_children():\n",
        "  for name_2, params in child.named_parameters():\n",
        "    print(name_2, params.requires_grad)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight False\n",
            "weight False\n",
            "bias False\n",
            "0.conv1.weight False\n",
            "0.bn1.weight False\n",
            "0.bn1.bias False\n",
            "0.conv2.weight False\n",
            "0.bn2.weight False\n",
            "0.bn2.bias False\n",
            "1.conv1.weight False\n",
            "1.bn1.weight False\n",
            "1.bn1.bias False\n",
            "1.conv2.weight False\n",
            "1.bn2.weight False\n",
            "1.bn2.bias False\n",
            "0.conv1.weight False\n",
            "0.bn1.weight False\n",
            "0.bn1.bias False\n",
            "0.conv2.weight False\n",
            "0.bn2.weight False\n",
            "0.bn2.bias False\n",
            "0.downsample.0.weight False\n",
            "0.downsample.1.weight False\n",
            "0.downsample.1.bias False\n",
            "1.conv1.weight False\n",
            "1.bn1.weight False\n",
            "1.bn1.bias False\n",
            "1.conv2.weight False\n",
            "1.bn2.weight False\n",
            "1.bn2.bias False\n",
            "0.conv1.weight False\n",
            "0.bn1.weight False\n",
            "0.bn1.bias False\n",
            "0.conv2.weight False\n",
            "0.bn2.weight False\n",
            "0.bn2.bias False\n",
            "0.downsample.0.weight False\n",
            "0.downsample.1.weight False\n",
            "0.downsample.1.bias False\n",
            "1.conv1.weight False\n",
            "1.bn1.weight False\n",
            "1.bn1.bias False\n",
            "1.conv2.weight False\n",
            "1.bn2.weight False\n",
            "1.bn2.bias False\n",
            "0.conv1.weight False\n",
            "0.bn1.weight False\n",
            "0.bn1.bias False\n",
            "0.conv2.weight False\n",
            "0.bn2.weight False\n",
            "0.bn2.bias False\n",
            "0.downsample.0.weight False\n",
            "0.downsample.1.weight False\n",
            "0.downsample.1.bias False\n",
            "1.conv1.weight False\n",
            "1.bn1.weight False\n",
            "1.bn1.bias False\n",
            "1.conv2.weight False\n",
            "1.bn2.weight False\n",
            "1.bn2.bias False\n",
            "weight True\n",
            "bias True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WVfy9h7ui1bv",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "resnet18 = resnet18.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet18.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IVh8E1tyi1b6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a6vC03jIj-qy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1354
        },
        "outputId": "924e0bcc-91c6-4598-fd4f-11b30ec37eb9"
      },
      "cell_type": "code",
      "source": [
        "resnet18 = train_model(resnet18, criterion, optimizer,\n",
        "                         exp_lr_scheduler, num_epochs=15)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 0.5387 Acc: 0.7112\n",
            "test Loss: 0.6026 Acc: 0.6658\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.5360 Acc: 0.7144\n",
            "test Loss: 0.6168 Acc: 0.6603\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.5353 Acc: 0.7142\n",
            "test Loss: 0.6024 Acc: 0.6667\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.5330 Acc: 0.7151\n",
            "test Loss: 0.6020 Acc: 0.6585\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.5326 Acc: 0.7174\n",
            "test Loss: 0.5990 Acc: 0.6639\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.5308 Acc: 0.7167\n",
            "test Loss: 0.6003 Acc: 0.6703\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.5332 Acc: 0.7177\n",
            "test Loss: 0.6015 Acc: 0.6658\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.5327 Acc: 0.7156\n",
            "test Loss: 0.6042 Acc: 0.6530\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.5344 Acc: 0.7236\n",
            "test Loss: 0.6048 Acc: 0.6539\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.5314 Acc: 0.7195\n",
            "test Loss: 0.6011 Acc: 0.6530\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.5312 Acc: 0.7158\n",
            "test Loss: 0.6004 Acc: 0.6667\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.5331 Acc: 0.7181\n",
            "test Loss: 0.6003 Acc: 0.6485\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.5322 Acc: 0.7193\n",
            "test Loss: 0.6000 Acc: 0.6667\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.5331 Acc: 0.7158\n",
            "test Loss: 0.6016 Acc: 0.6548\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.5326 Acc: 0.7161\n",
            "test Loss: 0.5994 Acc: 0.6576\n",
            "\n",
            "Training complete in 8m 54s\n",
            "Best val Acc: 0.670310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d846k__pAVde",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "o-SCaQh6whm9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7fe11d4b-6907-4c26-e931-105aeeebef48"
      },
      "cell_type": "code",
      "source": [
        "# # memory footprint support libraries/code\n",
        "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "# !pip install gputil\n",
        "# !pip install psutil\n",
        "# !pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 12.9 GB  | Proc size: 137.5 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Uq_YQqNHwxVG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}